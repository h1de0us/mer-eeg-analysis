{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dgl graph from connectivity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PATH = \"/Users/h1de0us/uni/mer-eeg-analysis/data/deap_filtered/s01_plv.npy\"\n",
    "connectivity_matrix = np.load(TEST_PATH)\n",
    "connectivity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.57803585, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33041863, 0.56471143, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.28629317, 0.28253806, 0.27283744, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.34106162, 0.56037416, 0.60070708, ..., 0.27732514, 0.        ,\n",
       "        0.        ],\n",
       "       [0.37746005, 0.45468193, 0.43395707, ..., 0.25628626, 0.71649264,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity_matrix = connectivity_matrix[:, :, -1]\n",
    "connectivity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "connectivity_matrix[connectivity_matrix < threshold] = 0 # remove weak connections\n",
    "connectivity_matrix += np.rot90(np.fliplr(connectivity_matrix)) # make the matrix symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(connectivity_matrix)\n",
    "nx_graph = nx_graph.to_directed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=32, num_edges=426,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graph = dgl.from_networkx(nx_graph, edge_attrs=['weight'])\n",
    "dgl_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = dgl_graph.number_of_nodes()\n",
    "dim_feedforward = 64\n",
    "\n",
    "centrality_encoding = nn.Embedding(n_nodes, dim_feedforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graph.in_degrees().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality = centrality_encoding(dgl_graph.in_degrees())\n",
    "centrality.shape # (n_nodes, dim_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 4\n",
    "spatial_encoding = nn.Embedding(n_nodes, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spd = dgl.shortest_dist(dgl_graph)\n",
    "spd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 4])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial = spatial_encoding(spd)\n",
    "spatial.shape # (n_nodes, n_nodes, n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, -1, -1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spd, paths = dgl.shortest_dist(dgl_graph, return_paths=True)\n",
    "paths[0, 2] # Each path is a vector that consists of edge IDs with paddings of -1 at the end. (via documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = paths[0, 2]\n",
    "path = path[path >= 0]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_encoder = nn.Embedding(n_nodes ** 2, n_heads)\n",
    "edge_features = dgl_graph.edata['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.4382,  0.2501, -0.6002,  0.1003], grad_fn=<MeanBackward1>),\n",
       " torch.Size([4]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, j = 12, 24\n",
    "\n",
    "_, path = dgl.shortest_dist(dgl_graph, i, return_paths=True)\n",
    "# path is a sequence of nodes, len(path) == max_path \n",
    "# -1 is a padding value\n",
    "path = path[j]\n",
    "path = path[path >= 0] # remove padding\n",
    "edge_embeds = edge_encoder(path) # (n_spd, n_heads)\n",
    "spd_features = edge_features[path] # (n_spd)\n",
    "result = torch.mean(edge_embeds * spd_features.unsqueeze(-1), dim=0)\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 data_path: str = \"../data/deap_filtered\",\n",
    "                 duration : float = 3.0,\n",
    "                 method : str = \"plv\",\n",
    "                 participants_range : tuple = (0, 32),\n",
    "                 n_trials=40):\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "        participants = [file[:-4] for file in os.listdir(data_path) if file.endswith('.dat')][participants_range[0]:participants_range[1]]\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for participant in tqdm(participants):\n",
    "            # labels\n",
    "            labels_for_participant = pickle.load(open(f\"{data_path}/{participant}.dat\", \"rb\"), encoding=\"latin1\")[\"labels\"]\n",
    "            self.labels.append(labels_for_participant)\n",
    "\n",
    "            # data\n",
    "            duration_str = str(duration)\n",
    "            prefix = f\"{data_path}/{participant}_{method}_{duration_str}_trial_\" # inside the collate_fn we add postfixes for all trials\n",
    "            self.paths.append(prefix)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # each dataset item is one participant\n",
    "        # for each participant, we have a list of 40 trials \n",
    "        # each trial is a tuple of (connectivity_matrix, label)\n",
    "        # connectivity_matrix is a 3D numpy array of shape (n_channels, n_channels, n_bands)\n",
    "        # label is a scalar\n",
    "        return {\n",
    "            \"path_prefix\": self.paths[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "            \"n_trials\": self.n_trials\n",
    "        }\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(participant): # participant is actually the whole batch, as there are 40 trials for each participant\n",
    "    matrices = []\n",
    "    labels = []\n",
    "\n",
    "    if isinstance(participant, list):\n",
    "        participant = participant[0]\n",
    "    for trial in range(participant[\"n_trials\"]):\n",
    "        path = participant[\"path_prefix\"] + str(trial) + \".npy\"\n",
    "        connectivity_matrix = torch.from_numpy(np.load(path)) # matrices for all bands\n",
    "        matrices.extend(torch.split(connectivity_matrix, 1, dim=-1)) # split along the last axis\n",
    "        labels.extend([participant[\"labels\"][trial] for b in range(connectivity_matrix.shape[-1])]) # replicate the label for each band\n",
    "\n",
    "    return {\n",
    "        \"matrices\": torch.stack(matrices, dim=0).squeeze(-1),\n",
    "        \"labels\": torch.as_tensor(labels) # n_trials * b_bands,  (valence, arousal, dominance, liking)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 4])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(dataset[0])[\"labels\"].shape #\n",
    "# 160 = n_trials * n_bands\n",
    "# 32 = n_channels\n",
    "# shape = n_trials * n_bands, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:03<00:00,  8.92it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# create datasets\n",
    "train_dataset = EEGDataset(participants_range=(1, 32))\n",
    "val_dataset = EEGDataset(participants_range=(33, 40))\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(model, \n",
    "                  batch, \n",
    "                  optimizer,\n",
    "                  criterion,\n",
    "                  device,\n",
    "                  is_train=True):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module, current model\n",
    "    :param batch: dict, a batch that is being processed\n",
    "    \"\"\"\n",
    "    for tensor_for_gpu in batch.keys():\n",
    "        batch[tensor_for_gpu] = batch[tensor_for_gpu].to(device)\n",
    "    predictions, attention = model(batch)\n",
    "    if type(predictions) is dict:\n",
    "        batch.update(predictions)\n",
    "    else:\n",
    "        batch[\"predictions\"] = predictions\n",
    "        batch[\"attention\"] = attention\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(batch[\"predictions\"], batch[\"labels\"])\n",
    "    if is_train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    batch[\"loss\"] = loss\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(epoch, model, optimizer, criterion, train_loader, device, log_step=5):\n",
    "    \"\"\"\n",
    "    Training logic for an epoch\n",
    "\n",
    "    :param epoch: Integer, current training epoch.\n",
    "    :return: A log that contains average loss and metric in this epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    # DEBUG\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    for batch_idx, batch in enumerate(\n",
    "            tqdm(train_loader, desc=\"train\")):\n",
    "        try:\n",
    "            batch = process_batch(model,\n",
    "                                batch,\n",
    "                                optimizer,\n",
    "                                criterion,\n",
    "                                device\n",
    "                                )\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(\"OOM on batch. Skipping batch.\")\n",
    "                for p in model.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        del p.grad  # free some memory\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "        print( # plot loss after every participant\n",
    "            \"Train Epoch: {} {} Loss: {:.6f}\".format(\n",
    "            epoch, batch_idx, batch[\"loss\"].item()\n",
    "        ))\n",
    "\n",
    "def evaluate_epoch(model, criterion, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate after training an epoch\n",
    "\n",
    "    :return: A log that contains information about the evaluation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(\n",
    "                tqdm(val_loader, desc=\"val\")):\n",
    "            batch = process_batch(model,\n",
    "                                batch,\n",
    "                                optimizer,\n",
    "                                criterion,\n",
    "                                device,\n",
    "                                is_train=False\n",
    "                                )\n",
    "            val_loss += batch[\"loss\"].item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(\"Val set: Average loss: {:.4f}\".format(val_loss))\n",
    "    return {\n",
    "        \"val_loss\": val_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 4])\n"
     ]
    }
   ],
   "source": [
    "one_batch_dataset = EEGDataset(participants_range=(1, 2))\n",
    "train_loader = torch.utils.data.DataLoader(one_batch_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "from src.model import GraphormerModel\n",
    "\n",
    "model = GraphormerModel(\n",
    "    n_nodes = 32,\n",
    "    n_layers = 1,\n",
    "    n_heads = 4,\n",
    "    embed_dim = 8,\n",
    "    dim_feedforward=16,\n",
    "\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for batch in train_loader:\n",
    "    predictions, attention = model(batch)\n",
    "    print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/31 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     evaluate_epoch(model, criterion, val_loader, device)\n",
      "Cell \u001b[0;32mIn[88], line 44\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, optimizer, criterion, train_loader, device, log_step)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     42\u001b[0m         tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout of memory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "Cell \u001b[0;32mIn[88], line 13\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(model, batch, optimizer, criterion, device, is_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tensor_for_gpu \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     12\u001b[0m     batch[tensor_for_gpu] \u001b[38;5;241m=\u001b[39m batch[tensor_for_gpu]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m predictions, attention \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(predictions) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     15\u001b[0m     batch\u001b[38;5;241m.\u001b[39mupdate(predictions)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/coursework/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/coursework/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/uni/mer-eeg-analysis/graphs/src/model/graphormer.py:93\u001b[0m, in \u001b[0;36mGraphormerModel.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     91\u001b[0m attentions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj_matrix \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatrices\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 93\u001b[0m     output, attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     95\u001b[0m     attentions\u001b[38;5;241m.\u001b[39mappend(attention)\n",
      "File \u001b[0;32m~/uni/mer-eeg-analysis/graphs/src/model/graphormer.py:117\u001b[0m, in \u001b[0;36mGraphormerModel._forward\u001b[0;34m(self, adj_matrix)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Edge Encoding\u001b[39;00m\n\u001b[1;32m    116\u001b[0m edge_features \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m edge_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_edge_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (n_nodes, n_nodes, n_heads)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m edge_encoding \u001b[38;5;241m=\u001b[39m edge_encoding\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# (n_heads, n_nodes, n_nodes)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m node_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_encoder(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes)) \u001b[38;5;66;03m# (n_nodes, embed_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/uni/mer-eeg-analysis/graphs/src/model/graphormer.py:150\u001b[0m, in \u001b[0;36mGraphormerModel.compute_edge_encoding\u001b[0;34m(self, graph, edge_features)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes):\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;66;03m# calculating indices of the edges that lie on the path between v_i and v_j\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m         _, path \u001b[38;5;241m=\u001b[39m \u001b[43mdgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshortest_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         path \u001b[38;5;241m=\u001b[39m path[j] \u001b[38;5;66;03m# path from i to j\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;66;03m# path is a sequence of nodes, len(path) == max_path \u001b[39;00m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;66;03m# -1 is a padding value\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/coursework/lib/python3.10/site-packages/dgl/transforms/functional.py:3988\u001b[0m, in \u001b[0;36mshortest_dist\u001b[0;34m(g, root, return_paths)\u001b[0m\n\u001b[1;32m   3985\u001b[0m masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(masks, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3987\u001b[0m u, v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(u), np\u001b[38;5;241m.\u001b[39marray(v)\n\u001b[0;32m-> 3988\u001b[0m edge_ids \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3989\u001b[0m paths[masks] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39masnumpy(edge_ids)\n\u001b[1;32m   3990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/coursework/lib/python3.10/site-packages/dgl/heterograph.py:3249\u001b[0m, in \u001b[0;36mDGLGraph.edge_ids\u001b[0;34m(self, u, v, return_uv, etype)\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu contains invalid node IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3248\u001b[0m v \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mprepare_tensor(\u001b[38;5;28mself\u001b[39m, v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mas_scalar(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsttype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m   3250\u001b[0m     v\n\u001b[1;32m   3251\u001b[0m ):\n\u001b[1;32m   3252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv contains invalid node IDs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_uv:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/coursework/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:153\u001b[0m, in \u001b[0;36msum\u001b[0;34m(input, dim, keepdims)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28minput\u001b[39m, dim, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "from src.model import GraphormerModel\n",
    "\n",
    "model = GraphormerModel(\n",
    "    n_nodes = 32,\n",
    "    n_layers = 1,\n",
    "    n_heads = 4,\n",
    "    embed_dim = 64,\n",
    "    dim_feedforward=32,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_epoch(epoch, model, optimizer, criterion, train_loader, device)\n",
    "    evaluate_epoch(model, criterion, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
